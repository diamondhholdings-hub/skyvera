---
phase: 01-foundation-and-data-integration
plan: 03
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src/lib/intelligence/claude/orchestrator.ts
  - src/lib/intelligence/claude/rate-limiter.ts
  - src/lib/intelligence/claude/prompts/system.ts
  - src/lib/intelligence/claude/prompts/account-intel.ts
  - src/lib/intelligence/claude/prompts/scenario-impact.ts
  - src/lib/intelligence/claude/prompts/nl-query.ts
autonomous: true

must_haves:
  truths:
    - "All Claude API requests flow through ClaudeOrchestrator.processRequest() -- no direct Anthropic SDK calls elsewhere"
    - "Rate limiter prevents more than 50 requests per 60 seconds, queuing excess requests instead of failing"
    - "HIGH priority requests (user waiting) are processed before LOW priority (background enrichment)"
    - "Same prompt submitted twice within 5 minutes returns cached response without API call"
    - "If Claude API returns 429, orchestrator retries with exponential backoff and jitter instead of crashing"
    - "If ANTHROPIC_API_KEY is missing, orchestrator returns a descriptive error Result, not an unhandled exception"
  artifacts:
    - path: "src/lib/intelligence/claude/orchestrator.ts"
      provides: "Central Claude API request routing and management"
      exports: ["ClaudeOrchestrator", "getOrchestrator"]
      min_lines: 100
    - path: "src/lib/intelligence/claude/rate-limiter.ts"
      provides: "Token bucket rate limiter for Claude API"
      exports: ["ClaudeRateLimiter"]
      min_lines: 40
    - path: "src/lib/intelligence/claude/prompts/system.ts"
      provides: "System prompt template with metric definitions injection"
      exports: ["buildSystemPrompt"]
  key_links:
    - from: "src/lib/intelligence/claude/orchestrator.ts"
      to: "src/lib/intelligence/claude/rate-limiter.ts"
      via: "awaits rate limiter before each API call"
      pattern: "rateLimiter\\.waitForSlot"
    - from: "src/lib/intelligence/claude/orchestrator.ts"
      to: "src/lib/cache/manager.ts"
      via: "caches Claude responses by prompt hash"
      pattern: "cache\\.get.*claude:"
    - from: "src/lib/intelligence/claude/prompts/system.ts"
      to: "src/lib/semantic/schema/financial.ts"
      via: "injects metric definitions into system prompt"
      pattern: "getMetricDefinition|METRIC_DEFINITIONS"
---

<objective>
Build the Claude API orchestration layer with centralized request routing, priority queue, rate limiting, response caching, and prompt templates.

Purpose: Research identifies Claude API rate limits as a DEMO STOPPER if not handled. The orchestrator prevents 429 errors by queueing requests, prioritizing user-facing queries, and caching responses. It also ensures consistent prompt engineering -- every Claude request gets the same semantic context injection, preventing hallucinations about business metrics.

Output: ClaudeOrchestrator singleton that all features use for Claude API access, with rate limiting (50 RPM), priority queue (HIGH/MEDIUM/LOW), response caching (5-15 min TTL), and prompt templates for each use case.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation-and-data-integration/01-RESEARCH.md

# Types and cache from Plan 01 and Plan 02 (will exist by execution time)
# Reference: src/lib/types/result.ts, src/lib/cache/manager.ts, src/lib/semantic/schema/financial.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build rate limiter and Claude orchestrator with priority queue and caching</name>
  <files>
    src/lib/intelligence/claude/rate-limiter.ts
    src/lib/intelligence/claude/orchestrator.ts
  </files>
  <action>
    **src/lib/intelligence/claude/rate-limiter.ts** -- Token bucket rate limiter for Claude API:

    Use `rate-limiter-flexible` library (RateLimiterMemory). Configure for Claude API Tier 1 limits:
    - 50 requests per 60 seconds (RPM limit)
    - Use execEvenly: true to distribute requests evenly across the window

    ClaudeRateLimiter class:
    - `waitForSlot(): Promise<void>` -- Consume 1 token. If rate limit exceeded, wait for msBeforeNext then retry. Use recursive retry with safety counter (max 5 retries to prevent infinite loops).
    - `getRemainingTokens(): number` -- For monitoring/display.
    - `isAvailable(): boolean` -- Quick check without consuming.

    **src/lib/intelligence/claude/orchestrator.ts** -- Central Claude API gateway:

    ```typescript
    interface ClaudeRequest {
      prompt: string
      systemPrompt?: string
      priority: 'HIGH' | 'MEDIUM' | 'LOW'
      context?: Record<string, unknown>
      maxTokens?: number
      temperature?: number
      cacheKey?: string  // Custom cache key, defaults to prompt hash
    }

    interface ClaudeResponse {
      content: string
      model: string
      inputTokens: number
      outputTokens: number
      cached: boolean
    }
    ```

    ClaudeOrchestrator class:
    - Constructor: Initialize Anthropic client (check for ANTHROPIC_API_KEY, if missing log warning but don't crash). Accept CacheManager via dependency injection. Initialize rate limiter.
    - `processRequest(request: ClaudeRequest): Promise<Result<ClaudeResponse>>`:
      1. Generate cache key: `claude:${hashPrompt(request.prompt + (request.systemPrompt || ''))}`. Use simple string hash (not crypto -- speed over security for cache keys).
      2. Check cache (TTL based on priority: HIGH=300s, MEDIUM/LOW=900s).
      3. If cache hit, return immediately with `cached: true`.
      4. Enqueue by priority. For demo, use a simple sorted array queue (not a full priority queue library). HIGH processes before MEDIUM before LOW.
      5. Wait for rate limiter slot.
      6. Call Anthropic SDK: `client.messages.create({ model: 'claude-sonnet-4-5-20250929', max_tokens, messages, system })`.
      7. Parse response, cache result, return as Result.
      8. On 429 error: Exponential backoff with jitter (1-2 seconds base, double each retry, max 3 retries). Log retry attempts.
      9. On other API errors: Return Result.err with descriptive error.
      10. On missing API key: Return Result.err('ANTHROPIC_API_KEY not configured').

    - `processRequestWithSemanticContext(request: ClaudeRequest, metricNames?: string[]): Promise<Result<ClaudeResponse>>`:
      Wrapper that auto-injects semantic metric definitions into the system prompt. Uses buildSystemPrompt() from prompts/system.ts. This is the preferred method for all feature code.

    - `batchProcess(requests: ClaudeRequest[]): Promise<Map<string, Result<ClaudeResponse>>>`:
      Process multiple requests respecting rate limits. Sort by priority. Process sequentially (rate limiter handles spacing). Return map of cacheKey -> response.

    - `getStats(): { totalRequests: number, cacheHits: number, apiCalls: number, errors: number, avgLatencyMs: number }`:
      Track request statistics for monitoring.

    Private helpers:
    - `hashPrompt(prompt: string): string` -- Simple hash (djb2 or similar). Fast, not cryptographic.
    - `withRetry<T>(fn: () => Promise<T>, maxRetries: number): Promise<T>` -- Exponential backoff with jitter.

    Singleton: Export `getOrchestrator(cache?: CacheManager): ClaudeOrchestrator`. Lazily initialized.

    IMPORTANT: Do NOT use `any` types. Use proper typing throughout. Import Result, ok, err from types.
  </action>
  <verify>
    `npx tsc --noEmit` passes. Create a temporary test script:
    1. Instantiate ClaudeOrchestrator with a CacheManager
    2. Verify rate limiter has 50 points / 60 seconds configured
    3. Verify getStats() returns zeroed stats initially
    4. Verify processRequest with missing API key returns Result with success=false and descriptive error message
    5. Verify hashPrompt produces consistent output for same input
    6. Verify cache key generation includes both prompt and system prompt

    Delete test file after verification.
  </verify>
  <done>ClaudeOrchestrator provides centralized Claude API access with rate limiting (50 RPM), priority queue, response caching, exponential backoff on 429, and graceful error handling. No direct Anthropic SDK calls needed elsewhere in the codebase.</done>
</task>

<task type="auto">
  <name>Task 2: Create prompt templates for all Claude use cases</name>
  <files>
    src/lib/intelligence/claude/prompts/system.ts
    src/lib/intelligence/claude/prompts/account-intel.ts
    src/lib/intelligence/claude/prompts/scenario-impact.ts
    src/lib/intelligence/claude/prompts/nl-query.ts
  </files>
  <action>
    **src/lib/intelligence/claude/prompts/system.ts** -- Base system prompt builder:

    `buildSystemPrompt(metricDefinitions: string, bu?: string): string` -- Returns system prompt:
    ```
    You are an AI business analyst for Skyvera, a multi-business unit SaaS company.
    ${bu ? `You are currently analyzing the ${bu} business unit.` : ''}

    BUSINESS CONTEXT:
    - Skyvera has 3 BUs: Cloudsense (~$8M quarterly), Kandy (~$3.3M quarterly), STL (~$1M quarterly)
    - Q1'26 budget cycle, fiscal year aligned to calendar year
    - Key concern: FY'25 EBITDA test FAILED, RR declining $336K, margin gap $918K

    METRIC DEFINITIONS (use ONLY these definitions):
    ${metricDefinitions}

    CONSTRAINTS:
    - If data is insufficient to answer accurately, respond: "Insufficient data to provide a reliable answer."
    - Never guess or hallucinate financial numbers. Only use provided data.
    - Cite the data source in your response (e.g., "Source: RR Summary sheet")
    - If asked about a metric not defined above, state it's not currently tracked.
    - Express currency in USD unless otherwise specified.
    - Round percentages to 1 decimal place, currency to nearest dollar.

    OUTPUT FORMAT:
    Always respond with valid JSON matching this structure:
    {
      "answer": "Your analysis here",
      "confidence": "HIGH" | "MEDIUM" | "LOW",
      "sources": ["Data source 1", "Data source 2"],
      "dataPoints": { "metricName": value }
    }
    ```

    **src/lib/intelligence/claude/prompts/account-intel.ts** -- Account intelligence prompt builder:

    `buildAccountIntelPrompt(customerName: string, financialData: CustomerFinancials, newsData?: NewsArticle[]): string`
    - Include customer financials (ARR, NRR, margin, renewal status, rank)
    - Include recent news if available
    - Ask for: executive summary, risk assessment, growth opportunities, recommended actions
    - Output format: JSON with { summary, riskLevel, risks[], opportunities[], recommendedActions[], confidence }

    **src/lib/intelligence/claude/prompts/scenario-impact.ts** -- Scenario analysis prompt builder:

    `buildScenarioPrompt(scenario: { type: 'financial' | 'headcount' | 'customer', description: string, parameters: Record<string, number>, baselineData: Record<string, number> }): string`
    - Include baseline metrics
    - Describe the scenario change
    - Ask for: impact analysis, affected metrics with before/after values, risk assessment, recommendation
    - Output format: JSON with { impactSummary, affectedMetrics[{ name, before, after, change }], risks[], recommendation, confidence }

    **src/lib/intelligence/claude/prompts/nl-query.ts** -- Natural language query prompt builder:

    `buildNLQueryPrompt(query: string, availableData: string[], previousContext?: string): string`
    - Include list of available data sources and metrics
    - Include previous conversation context if multi-turn
    - Ask Claude to: interpret the query, identify relevant metrics, provide answer with data
    - If query is ambiguous: return clarification question
    - Output format: JSON with { interpretation, answer, dataPoints, needsClarification, clarificationQuestion?, confidence }

    ALL prompt builders must:
    - Accept typed parameters (no `any`)
    - Return string (the prompt text)
    - Include output format specification in the prompt
    - Be pure functions (no side effects, no API calls)
  </action>
  <verify>
    `npx tsc --noEmit` passes. Verify:
    1. buildSystemPrompt('ARR: Annual Recurring Revenue') returns string containing "METRIC DEFINITIONS"
    2. buildAccountIntelPrompt('Telstra', { arr: 1972000 }) returns string containing "Telstra"
    3. buildScenarioPrompt with financial type returns string containing "impact analysis"
    4. buildNLQueryPrompt('What is Cloudsense ARR?', ['ARR', 'EBITDA']) returns string containing the query
    5. All functions are pure (no side effects, return strings)
  </verify>
  <done>Prompt templates exist for all 4 Claude use cases (system, account intelligence, scenario impact, NL query). All are typed, pure functions that build structured prompts with output format specifications. The orchestrator uses these to ensure consistent Claude interactions across all features.</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with all orchestrator code
2. ClaudeOrchestrator handles missing API key gracefully (Result.err, not crash)
3. Rate limiter configured for 50 RPM with even distribution
4. Prompt templates produce well-structured prompts for all use cases
5. Response caching prevents duplicate API calls for identical prompts
6. Priority queue processes HIGH before MEDIUM before LOW
</verification>

<success_criteria>
- ClaudeOrchestrator singleton handles all Claude API communication
- Rate limiter prevents >50 RPM with token bucket algorithm
- Priority queue (HIGH/MEDIUM/LOW) ensures user-facing requests process first
- Response caching with 5-15 min TTL (priority-dependent) prevents duplicate API calls
- Exponential backoff with jitter on 429 errors (max 3 retries)
- 4 prompt templates: system, account-intel, scenario-impact, nl-query
- Graceful error handling throughout (Result types, no unhandled exceptions)
- Zero TypeScript compilation errors
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-and-data-integration/01-03-SUMMARY.md`
</output>
