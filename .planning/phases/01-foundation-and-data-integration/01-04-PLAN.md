---
phase: 01-foundation-and-data-integration
plan: 04
type: execute
wave: 3
depends_on: ["01-02", "01-03"]
files_modified:
  - src/lib/data/adapters/base.ts
  - src/lib/data/adapters/excel/parser.ts
  - src/lib/data/adapters/excel/transforms.ts
  - src/lib/data/adapters/external/newsapi.ts
  - src/lib/data/registry/connector-factory.ts
  - scripts/parse_excel_to_json.py
  - src/app/api/health/route.ts
autonomous: true

must_haves:
  truths:
    - "ExcelAdapter parses the actual Skyvera budget file and extracts all 140 customer records across 4 BUs without errors"
    - "ExcelAdapter extracts financial summary data (RR, NRR, COGS, margins) from P&Ls sheets for each BU"
    - "All extracted customer data passes Zod validation (CustomerSchema.safeParse succeeds for every record)"
    - "NewsAPIAdapter fetches articles for a company name and returns validated NewsArticle array"
    - "NewsAPIAdapter handles missing API key, rate limits, and network errors without crashing"
    - "ConnectorFactory routes queries to correct adapter and handles adapter failures gracefully"
    - "GET /api/health returns 200 with status of all adapters and cache stats"
  artifacts:
    - path: "src/lib/data/adapters/base.ts"
      provides: "DataAdapter interface all adapters implement"
      exports: ["DataAdapter", "AdapterQuery", "DataResult"]
    - path: "src/lib/data/adapters/excel/parser.ts"
      provides: "Excel budget file parser using Python openpyxl"
      exports: ["ExcelAdapter"]
      min_lines: 100
    - path: "src/lib/data/adapters/external/newsapi.ts"
      provides: "NewsAPI.ai integration for business intelligence"
      exports: ["NewsAPIAdapter"]
      min_lines: 80
    - path: "src/lib/data/registry/connector-factory.ts"
      provides: "Adapter registry for unified data access"
      exports: ["ConnectorFactory", "getConnectorFactory"]
    - path: "src/app/api/health/route.ts"
      provides: "Health check endpoint for integration verification"
      exports: ["GET"]
  key_links:
    - from: "src/lib/data/adapters/excel/parser.ts"
      to: "scripts/parse_excel_to_json.py"
      via: "child_process.execFile to run Python parser"
      pattern: "execFile|spawn.*python"
    - from: "src/lib/data/adapters/excel/parser.ts"
      to: "src/lib/semantic/validator.ts"
      via: "validates all extracted data through DataValidator"
      pattern: "validator\\.validate"
    - from: "src/lib/data/adapters/external/newsapi.ts"
      to: "src/lib/cache/manager.ts"
      via: "caches news responses with 15-min TTL"
      pattern: "cache\\.get.*news:"
    - from: "src/lib/data/registry/connector-factory.ts"
      to: "src/lib/data/adapters/base.ts"
      via: "registers and routes to DataAdapter implementations"
      pattern: "adapters\\.get|adapters\\.set"
    - from: "src/app/api/health/route.ts"
      to: "src/lib/data/registry/connector-factory.ts"
      via: "calls healthCheck on all adapters"
      pattern: "healthCheck"
---

<objective>
Build the Excel data adapter (reusing Python openpyxl), NewsAPI.ai adapter, connector factory, and health check endpoint. Wire everything together with the semantic layer and cache from prior plans.

Purpose: This is the data foundation that makes real business data accessible. The Excel adapter extracts all 140 customers and financial metrics from the actual Skyvera budget file. The NewsAPI adapter provides real-time business intelligence. The connector factory provides a unified interface for all data access. The health endpoint proves the full stack works end-to-end.

Output: Working data pipeline: Excel file -> Python parser -> Node.js adapter -> Zod validation -> Cache -> Semantic layer. Plus NewsAPI integration and health check endpoint.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation-and-data-integration/01-RESEARCH.md

# Existing Python extraction logic to model from
@scripts/extract_all_customers.py

# Existing customer data structure
@data/customers_cloudsense_all.json

# Types, semantic layer, cache, and orchestrator from Plans 01-03 (will exist)
# src/lib/types/*, src/lib/semantic/*, src/lib/cache/*, src/lib/intelligence/claude/*
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build Excel adapter with Python parser bridge and NewsAPI adapter</name>
  <files>
    src/lib/data/adapters/base.ts
    src/lib/data/adapters/excel/parser.ts
    src/lib/data/adapters/excel/transforms.ts
    src/lib/data/adapters/external/newsapi.ts
    scripts/parse_excel_to_json.py
  </files>
  <action>
    **src/lib/data/adapters/base.ts** -- DataAdapter interface:
    ```typescript
    export interface DataAdapter {
      name: string
      connect(): Promise<Result<void>>
      query(query: AdapterQuery): Promise<Result<DataResult>>
      healthCheck(): Promise<boolean>
      disconnect(): Promise<void>
    }

    export interface AdapterQuery {
      type: 'customers' | 'financials' | 'subscriptions' | 'news'
      filters?: {
        bu?: string
        customerName?: string
        quarter?: string
        limit?: number
      }
    }

    export interface DataResult {
      data: unknown[]
      source: string
      timestamp: Date
      count: number
    }
    ```

    **scripts/parse_excel_to_json.py** -- Enhanced Python parser that outputs comprehensive JSON:

    Reuse the logic from `scripts/extract_all_customers.py` but output a comprehensive JSON structure via stdout. The script should:
    1. Accept command line argument: `--type customers|financials|all`
    2. Parse the Excel file `2025-12-11 Skyvera - Budget - Q1'26 - For Todd.xlsx`
    3. For `--type customers`: Extract ALL customers from RR Input and NRR Input sheets across ALL BUs. Output JSON matching the existing data/customers_*.json structure. Include subscriptions.
    4. For `--type financials`: Extract P&L summary data per BU from P&Ls sheets. Output JSON with: bu, totalRR, totalNRR, totalRevenue, cogs, headcountCost, vendorCost, ebitda, netMargin for each BU.
    5. For `--type all`: Output both customers and financials in a single JSON object.
    6. Output goes to STDOUT as valid JSON (print statements for progress go to STDERR).
    7. Handle errors gracefully: if a sheet doesn't exist or data is malformed, log to STDERR and continue with available data.
    8. Use `data_only=True` in load_workbook to get calculated values.

    IMPORTANT: Reference the existing column mappings from `scripts/extract_all_customers.py`:
    - RR Input: row[0]=company, row[1]=customer_name, row[3]=sub_id, row[6]=arr, row[8]=renewal_qtr, row[9]=will_renew, row[11]=projected_arr
    - NRR Input: similar structure for non-recurring revenue
    - P&Ls: Need to inspect to find BU summary rows (revenue, COGS, margins)

    The Python script should also extract from:
    - RR Summary sheet: Total RR per BU, decline metrics
    - NRR Summary sheet: Total NRR per BU
    - P&Ls sheets: Revenue, COGS, expenses per BU
    For financial data that can't be reliably extracted from P&Ls (complex formulas), use the existing customer JSON aggregation (sum RR/NRR from customers per BU).

    **src/lib/data/adapters/excel/parser.ts** -- ExcelAdapter class:
    - `connect()`: Run `parse_excel_to_json.py --type all` via `child_process.execFile('python3', [...])`. Parse stdout JSON. Store in memory. Validate ALL records through DataValidator. Log validation failures but don't reject records with minor issues (use coercion where safe). Return Result.
    - `query(query)`: Filter in-memory data by query params (bu, customerName). Return DataResult.
    - `healthCheck()`: Return true if data loaded and not empty.
    - `disconnect()`: Clear in-memory data.
    - Store parsed data in Maps: `customersByBU: Map<string, Customer[]>`, `financialsByBU: Map<string, FinancialMetrics>`.
    - Parse ONCE at connect(), serve from memory after that. This is the "parse once at startup" pattern from research.
    - Handle Python not found, file not found, parse errors gracefully with Result.err.

    **src/lib/data/adapters/excel/transforms.ts** -- Transform functions:
    - `transformRawCustomer(raw: Record<string, unknown>): Result<Customer>` -- Transform Python output to validated Customer type
    - `transformRawFinancials(raw: Record<string, unknown>): Result<FinancialMetrics>` -- Transform Python output to validated FinancialMetrics type
    - `aggregateByBU(customers: Customer[]): Map<string, BUFinancialSummary>` -- Aggregate customer data into BU-level summaries

    **src/lib/data/adapters/external/newsapi.ts** -- NewsAPIAdapter class:
    - `connect()`: Verify NEWSAPI_KEY exists. If not, log warning and mark adapter as "degraded" (not failed).
    - `query(query)`: Fetch news for customerName. Use `fetch()` to call NewsAPI.ai article search endpoint: `https://eventregistry.org/api/v1/article/getArticles`. Request body: `{ keyword: customerName, lang: 'eng', articlesCount: query.filters?.limit || 5, articlesSortBy: 'date' }`. Wrap response in Result. Validate with NewsArticleSchema.
    - Use CacheManager with CACHE_TTL.NEWS (15 min) to cache responses per customer.
    - If API key missing: return Result.err('NEWSAPI_KEY not configured').
    - If rate limited (429): return Result.err with retry info.
    - If network error: return Result.err with descriptive message.
    - `healthCheck()`: Return true if API key configured. Try a minimal API call if needed.
    - `disconnect()`: No-op.

    Strategy for 100 req/day free tier limit: Adapter fetches on-demand per customer, NOT batch for all 140. Cache aggressively (15 min). For demo, only ~20-30 unique customers will be viewed. If limit hit, return cached data or graceful degradation message.
  </action>
  <verify>
    1. `python3 scripts/parse_excel_to_json.py --type customers 2>/dev/null | python3 -m json.tool | head -20` outputs valid JSON with customer data
    2. `python3 scripts/parse_excel_to_json.py --type all 2>/dev/null | python3 -c "import sys,json; d=json.load(sys.stdin); print(f'Customers: {sum(len(v) for v in d.get(\"customers\",{}).values())}')"` shows ~140 customers
    3. `npx tsc --noEmit` passes
    4. ExcelAdapter.connect() successfully parses the real Excel file
    5. ExcelAdapter.query({ type: 'customers', filters: { bu: 'Cloudsense' } }) returns Result with Cloudsense customers
    6. NewsAPIAdapter handles missing API key gracefully
  </verify>
  <done>Excel adapter parses real Skyvera budget file via Python bridge and serves validated customer/financial data from memory. NewsAPI adapter fetches and caches business intelligence. Both implement DataAdapter interface.</done>
</task>

<task type="auto">
  <name>Task 2: Build connector factory, wire semantic layer to real adapters, create health endpoint</name>
  <files>
    src/lib/data/registry/connector-factory.ts
    src/app/api/health/route.ts
  </files>
  <action>
    **src/lib/data/registry/connector-factory.ts** -- ConnectorFactory class:

    - `register(adapter: DataAdapter): void` -- Register an adapter by name.
    - `async initialize(): Promise<{ adapter: string, status: 'connected' | 'degraded' | 'failed', error?: string }[]>` -- Call connect() on all registered adapters. Return status of each. Don't fail if one adapter fails (graceful degradation).
    - `getData(source: string, query: AdapterQuery): Promise<Result<DataResult>>` -- Route to correct adapter.
    - `getDataParallel(requests: Array<{ source: string, query: AdapterQuery }>): Promise<Map<string, Result<DataResult>>>` -- Fetch from multiple adapters in parallel using Promise.allSettled.
    - `healthCheck(): Promise<Map<string, boolean>>` -- Check all adapters.
    - `getAdapterStatus(): Map<string, 'connected' | 'degraded' | 'failed'>` -- Current status of all adapters.

    Singleton: Export `getConnectorFactory(): ConnectorFactory`. On first call, registers ExcelAdapter and NewsAPIAdapter, calls initialize().

    Wire the semantic layer: Update the SemanticResolver's DataProvider to use ConnectorFactory instead of MockDataProvider. Create a `RealDataProvider` that implements the DataProvider interface by calling `connectorFactory.getData('excel', ...)`. If Plan 02's SemanticResolver already has a MockDataProvider, swap it for RealDataProvider. The SemanticResolver should accept a DataProvider in its constructor, so this is a simple swap.

    **src/app/api/health/route.ts** -- Health check API endpoint:

    ```typescript
    import { NextResponse } from 'next/server'

    export async function GET() {
      const factory = await getConnectorFactory()
      const adapterHealth = await factory.healthCheck()
      const cacheStats = getCacheManager().stats()
      const orchestratorStats = getOrchestrator().getStats()

      return NextResponse.json({
        status: 'ok',
        timestamp: new Date().toISOString(),
        adapters: Object.fromEntries(adapterHealth),
        cache: cacheStats,
        orchestrator: orchestratorStats,
        environment: {
          anthropicKeyConfigured: !!process.env.ANTHROPIC_API_KEY,
          newsApiKeyConfigured: !!process.env.NEWSAPI_KEY,
          databaseUrl: process.env.DATABASE_URL ? 'configured' : 'missing',
        }
      })
    }
    ```

    After building everything, run the full integration test:
    1. Start the dev server: `npm run dev`
    2. Call `curl http://localhost:3000/api/health`
    3. Verify response shows: adapters.excel=true, cache stats, environment vars status
    4. Stop dev server
  </action>
  <verify>
    1. `npx tsc --noEmit` passes
    2. `npm run build` succeeds
    3. Start dev server, `curl http://localhost:3000/api/health` returns JSON with adapters, cache, orchestrator stats
    4. Health endpoint shows excel adapter connected (parsed real data)
    5. Health endpoint shows newsapi adapter status (degraded if no key, connected if key present)
    6. ConnectorFactory.getData('excel', { type: 'customers', filters: { bu: 'Cloudsense' } }) returns Cloudsense customers
  </verify>
  <done>ConnectorFactory provides unified data access across all adapters. Semantic layer wired to real data via RealDataProvider. Health endpoint verifies full stack: adapters, cache, orchestrator. Phase 1 foundation is complete and integration-tested.</done>
</task>

</tasks>

<verification>
1. `npm run build` completes with zero errors
2. `python3 scripts/parse_excel_to_json.py --type all` extracts all 140 customers from real Excel file
3. `curl http://localhost:3000/api/health` returns 200 with all adapter statuses
4. Excel adapter serves validated customer data from memory after single parse
5. NewsAPI adapter handles missing key gracefully (degraded, not failed)
6. ConnectorFactory routes queries to correct adapter
7. SemanticResolver uses real data from adapters (not mock)
8. All data passes Zod validation at boundaries
9. Cache stores and retrieves data with TTL
</verification>

<success_criteria>
- Excel adapter parses real Skyvera budget file extracting all ~140 customers across 4 BUs
- All extracted data validated through Zod schemas (CustomerSchema, FinancialMetricsSchema)
- NewsAPI adapter integrates with NewsAPI.ai with caching and graceful degradation
- ConnectorFactory provides unified data access with parallel fetching
- Health endpoint at /api/health shows status of all system components
- Semantic layer resolves metrics from real Excel data (not mock)
- End-to-end data pipeline works: Excel -> Python -> Node.js -> Validation -> Cache -> API
- Zero TypeScript compilation errors
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-and-data-integration/01-04-SUMMARY.md`
</output>
